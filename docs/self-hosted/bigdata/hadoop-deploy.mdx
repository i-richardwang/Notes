---
title: "Hadoop 集群部署"
description: ""
---


:::caution
这是一篇早年学习大数据知识时的折腾笔记，根据某培训机构的教程实操了Hadoop集群部署的详细过程。由于时间较早，部分内容可能已经过时，仅供参考。
:::

import { Steps } from '@theme';

学习中以三台虚拟机为例，主机名分别为hadoop01、hadoop02、hadoop03，系统为RockyLinux 8。

## 环境准备

### 虚拟机创建

:::tip
若多台虚拟机使用克隆的方式创建，需要按如下步骤分别修改主机名和静态ip地址，避免冲突。若各个虚拟机采用独立安装，则可在安装时直接配置好主机名和静态ip地址。
:::


<Steps>
### 修改主机名

```bash
hostnamectl set-hostname hadoop01 # hadoop02、hadoop03
```

### 修改静态 ip 地址

```bash
vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

```bash
...
BOOTPROTO=static
...
IPADDR="192.168.1.2"    # 每台虚拟机的 ip 地址不同
NETMASK="255.255.255.0" # 子网掩码，一般不用修改
GATEWAY="192.168.1.1"   # 网关地址
DNS1="192.168.1.1"      # DNS地址，可与网关地址相同
```
</Steps>

### 用户配置

:::caution
用户配置可以通过 xshell `发送键入到所有会话窗口` 的功能，同时在三台主机上执行，可以简化 ssh 免密登录的重复操作。否则需要在每台主机上分别执行。
:::

<Steps>
### 配置 hosts 主机名映射

```bash
vim /etc/hosts
```

```
192.168.100.61 hadoop01
192.168.100.62 hadoop02
192.168.100.63 hadoop03
```

### 配置 root 用户 ssh 免密登录

1. 生成密钥对

    ```bash
    ssh-keygen -t rsa
    ```

2. 将公钥分发到各个节点

    ```bash
    ssh-copy-id hadoop01
    ssh-copy-id hadoop02
    ssh-copy-id hadoop03
    ```

### 创建 hadoop 用户

```bash
useradd hadoop
passwd hadoop
```

### 配置 hadoop 用户 sudo 权限

```bash
vim /etc/sudoers
```

:::caution
以下配置需要在 %wheel ALL=(ALL) ALL 之后添加，否则无效。因为所有用户都在 %wheel 组中，若在 %wheel 之前添加，则会被之后的 %wheel 这一行配置覆盖。
:::

```bash
hadoop ALL=(ALL) NOPASSWD: ALL
```

### 配置 hadoop 用户 ssh 免密登录

1. 切换到 hadoop 用户
    ```bash
    su - hadoop
    ```

2. 生成密钥对
    ```bash
    ssh-keygen -t rsa
    ```

3. 将公钥分发到各个节点
    ```bash
    ssh-copy-id hadoop01
    ssh-copy-id hadoop02
    ssh-copy-id hadoop03
    ```
</Steps>

### 系统配置

<Steps>
### 关闭防火墙

```bash
systemctl stop firewalld
systemctl disable firewalld.service
```

### 关闭 SELinux

```bash
vim /etc/selinux/config
```

```bash
...
SELINUX=disabled
...
```

### 永久关闭 swap

```bash
swapoff -a
vim /etc/fstab
```

```bash
# 注释掉 swap 行
...
#/dev/mapper/cl-swap swap                    swap    defaults        0 0
...
```

### 配置时间同步

Rocky Linux 9 默认使用 chrony 作为时间同步服务。而 CentOS 7/8 默认使用 ntpd 作为时间同步服务。

```bash
vim /etc/chrony.conf
```

```bash
...
server ntp.aliyun.com iburst
...
```

```bash
systemctl restart chronyd && systemctl status chronyd
systemctl start chronyd
systemctl enable chronyd
```
</Steps>

### 安装 JDK

<Steps>
### 创建目录

1. 创建目录
    ```bash
    mkdir -p /opt/bigdata # 用于存放软件
    mkdir -p /opt/software # 用于存放安装包
    ```

2. 授权给 hadoop 用户
    ```bash
    chown -R hadoop:hadoop /opt/bigdata
    chown -R hadoop:hadoop /opt/software
    ```

### 上传 `jdk-8u212-linux-x64.tar.gz` 到 `/bigdata/software` 目录

### 解压
```bash
tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/bigdata
```

### 创建软链接
```bash
ln -s /opt/bigdata/jdk1.8.0_212 /opt/bigdata/jdk
```

### 配置环境变量
```bash
vim /etc/profile.d/bigdata.sh
```

```bash
export JAVA_HOME=/opt/bigdata/jdk
export PATH=$PATH:$JAVA_HOME/bin
```

### 使环境变量生效


> 通过 `source` 命令使环境变量生效，不需要重启系统，但是只对当前 shell 会话生效，若同时打开多个 shell 会话，则需要在每个 shell 会话中执行此命令，或者重启系统。


```bash
source /etc/profile.d/bigdata.sh
```

### 配置 JAVA 执行程序的软链接（可选）

```bash
ln -s /opt/bigdata/jdk/bin/java /usr/bin/java
ln -s /opt/bigdata/jdk/bin/jps /usr/bin/jps
```
</Steps>

## HDFS 部署

### 节点规划

| 主机名   | 角色                        |
| -------- | --------------------------- |
| hadoop01 | NameNode、DataNode          |
| hadoop02 | DataNode                    |
| hadoop03 | DataNode、SecondaryNameNode |

### 准备程序文件

<Steps>
### 下载 Hadoop 程序包

> 若下载速度过慢，可更换使用国内镜像如 [清华大学开源软件镜像站](https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/) 下载

```bash
cd /opt/software
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
```

### 解压

```bash
tar -zxvf /opt/software/hadoop-3.3.4.tar.gz -C /opt/bigdata
```

### 创建软链接

```bash
ln -s /opt/bigdata/hadoop-3.3.4 /opt/bigdata/hadoop
```
</Steps>

### 配置步骤

<Steps>

### 配置环境变量

    ```bash
    vim /etc/profile.d/bigdata.sh
    ```

    ```bash
    export HADOOP_HOME=/opt/bigdata/hadoop
    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    ```

    ```bash
    source /etc/profile.d/bigdata.sh
    ```

### 配置 workers

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/workers
    ```

    ```bash
    hadoop01
    hadoop02
    hadoop03
    ```

### 配置 core-site.xml

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/core-site.xml
    ```

    ```xml
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop01:8020</value>
        </property>
    ```

### 配置 hdfs-site.xml

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/hdfs-site.xml
    ```

> 针对副本数量 `dfs.replication`，由于我们在家中部署时，多数情况下三台虚拟机均在同一台物理机上和硬盘上，设置多个副本没有实际意义，反而浪费磁盘空间，所以设置为 1。生产环境中，需要修改为 3。

    ```xml
        <!-- namenode地址 -->
        <property>
            <name>dfs.namenode.http-address</name>
            <value>hadoop01:9870</value>
        </property>
        <!-- secondarynamenode地址 -->
        <property>
            <name>dfs.namenode.secondary.http-address</name>
            <value>hadoop03:9868</value>
        </property>
        <!-- 副本数量 -->
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
        <!-- 指定哪些节点作为 NameNode -->
        <property>
            <name>dfs.namenode.hosts</name>
            <value>hadoop01, hadoop02, hadoop03</value>
        </property>
    ```

### 分发到其他节点


> 文件夹 `/opt/bigdata/hadoop-3.3.4` 只可在集群初次启动之前分发，若已启动过，不可再分发，因为每个节点生成的数据不同，分发后会导致集群损坏。


    ```bash
    xsync /opt/bigdata/hadoop-3.3.4
    ```
</Steps>

### HDFS 集群启动

<Steps>
### 格式化 NameNode

    ```bash
    su - hadoop
       ```

    ```bash
    hdfs namenode -format
       ```

### 启动 HDFS

    ```bash
    start-dfs.sh
       ```

### 查看进程

    ```bash
    jps
       ```

### 停止 HDFS

    ```bash
    stop-dfs.sh
       ```
</Steps>

### 访问 HDFS

1. 访问 NameNode

    ```bash
    http://hadoop01:9870
       ```

2. 访问 DataNode

    ```bash
    http://hadoop02:9864
    http://hadoop03:9864
       ```

3. 访问 SecondaryNameNode

    ```bash
    http://hadoop03:9868
       ```

## YARN 部署

### 节点规划

| 主机名   | 角色                         |
| -------- | ---------------------------- |
| hadoop01 | Nodemanager                  |
| hadoop02 | ResourceManager、Nodemanager |
| hadoop03 | Nodemanager                  |

### 配置步骤

<Steps>
### 配置 yarn-site.xml

```bash
vim /opt/bigdata/hadoop/etc/hadoop/yarn-site.xml
```

```xml
    <!-- 为 MapReduce 开启 shuffle 服务 -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 设置ResourceManager的节点 -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop02</value>
    </property>
    <!-- 设置环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    <!-- 关闭yarn对虚拟内存的检查 -->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
    <!-- 开启日志聚合 -->
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <!-- 设置 历史服务器 日志聚合 URL -->
    <property>
        <name>yarn.log.server.url</name>
        <value>http://hadoop01:19888/jobhistory/logs</value>
    </property>
    <!-- 设置日志保留时间为 30 天 -->
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>2592000</value>
    </property>


    <!-- 选择公平调度器 -->
    <property>
        <name>yarn.resourcemanager.scheduler.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
    </property>
```

### 配置 mapred-site.xml

```bash
vim /opt/bigdata/hadoop/etc/hadoop/mapred-site.xml
```

```xml
    <!-- 设置MapReduce框架运行在YARN上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <!-- 设置MapReduce的JobHistoryServer的地址 -->
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>hadoop01:10020</value>
    </property>
    <!-- 设置MapReduce的JobHistoryServer的web地址 -->
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>hadoop01:19888</value>
    </property>
```

### 分发配置文件

> 注意只分发 /hadoop-3.3.4/etc/hadoop 配置文件夹，切勿同步整个 /opt/bigdata/hadoop-3.3.4 文件夹。

    ```bash
    xsync /opt/bigdata/hadoop-3.3.4/etc/hadoop
    ```
</Steps>

### 启动 YARN 集群启动

<Steps>
### 启动 YARN

```bash
start-yarn.sh
```

### 启动历史服务器

```bash
hadoop --daemon start historyserver
```

### 停止 YARN

```bash
hadoop --daemon stop historyserver
stop-yarn.sh
```

</Steps>

### 访问 YARN 集群

1. 访问 ResourceManager

    ```bash
    http://hadoop02:8088
       ```

2. 访问历史服务器

    ```bash
    http://hadoop01:19888
       ```
